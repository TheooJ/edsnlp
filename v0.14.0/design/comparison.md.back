# Features and comparison to other NLP libraries

### Spacy

SpaCy is a free, open-source library for fast and advanced Natural Language Processing in Python. It features many NLP components, including tokenization, part-of-speech tagging, named entity recognition, dependency parsing, word vectors and more. It is shipped with a deep learning library, Thinc, which is used to train neural network models.

EDS-NLP started as a wrapper around Spacy, and still uses it for many of its core functions. Most notably, EDS-NLP uses spaCy's data structures to store documents and annotations. This allows EDS-NLP to use spaCy's built-in visualizers, and benefit from a the interoperability with other spaCy-based tools.

/* We now explain below how we share a lot of spacy API, and tried to make it as similar as possible, while using pytorch as a deep learning backend instead of thinc. */

EDS-NLP features a new pipelining system for deep-learning and rule-based NLP based on Pytorch instead of Thinc. This allows for complex models to be built, while benefiting from both the flexibility and performance of pytorch and the ease of use of spaCy's API.

We list below the main features to compare pipeline systems of EDS-NLP and spaCy:

|                                                      | EDS-NLP       | spaCy       |
|------------------------------------------------------|---------------|-------------|
| Deep learning backend                                | Pytorch       | Thinc       |
| Compatibility with other deep-learning libraries     | No            | Yes         |
| Multi-task learning with shared layers               | Yes           | Yes         |
| Hybrid models                                        | Yes           | Yes         |
| Multi-gpu training                                   | Yes           | No          |
| Multi-gpu inference                                  | Yes           | No          |
| Compatibility with pytorch wrappers                  | Yes           | No          |
| Smart decoupling between preprocessing and inference | Yes           | No          |
| Model compilation (pytorch)                          | Yes           | No          |
| Language model pre-training                          | Supported     | Unsupported |
| Train from                                           | Notebook, CLI | CLI         |

# Features roadmap

- [ ] Sub-document batching
- [ ] Span qualifier
- [ ] Pytorch-lightning demo
- [ ] BERT pre-training / LLM finetuning
- [ ] Multi-gpu inference
- [x] Load/train from config
- [x] Load/train from model
- [ ] Infer defaults from signature
