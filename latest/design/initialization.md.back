# The initialization conundrum

The challenge is to initialize an NLP pipeline with components that require data-dependent arguments or need to be called during the data loading process. A striking example of this issue is the sentence classifier component that needs to align entity labels of the raw data with the automatically extracted sentences.

## Attempts

### Proposed solution: `CurriedFactory`
The CurriedFactory class allows partial initialization of components for essential operations during data loading. It stores the component class and its initialization arguments. Calling methods like `pipe` or `__call__` on it will raise an exception, as the component is not fully initialized.
This solution provides a balance between allowing users to run components when loading the dataset and enabling the filling of missing arguments depending on the data before calling the __init__ methods.

### Alternative 1: dynamic initialization
The dynamic initialization alternative uses a `PipelineInitializer` class to add components on-the-fly during data loading. This approach allows filling in the missing initialization arguments for components based on the data, as it is annotated on documents. However, this method is complex and not modular enough, leading to difficulties when adding new components or changing the pipeline structure.

### Alternative 2: manual creation of a supervised dataset

This alternative involves manually creating a supervised dataset, storing annotated documents, and loading them when initializing the pipeline. This approach can pose issues, such as:
- Synchronization problems between components and data, leading to inconsistencies and potential errors.
- Inflexibility when handling different formats, as the solution is tied to specific formats like BRAT.
- Components that require data to be initialized (e.g., embedding layers) may not have the necessary data available.

### Alternative 3: instantiate a full pipeline and call relevant components
This alternative suggests instantiating the full pipeline (even without the labels for some components) and letting users create a load_data function that calls relevant components depending on whether they are trainable or not. This solution could lead to difficulties in:

- serializing and deserializing the pipeline, as components might require a `post_init` method to update based on the data.
- ensuring an instantiated component is ready to be trained or used, as some components might still require data-dependent arguments to function correctly.

## Conclusion
The proposed solution with the CurriedFactory class addresses the initialization conundrum by allowing users to call specific components during data loading without fully initializing them. Once the data is processed, the components can be fully initialized and added to the pipeline. This approach simplifies the initialization process, ensuring the pipeline is ready to be trained or used while making it easier to serialize and deserialize.
