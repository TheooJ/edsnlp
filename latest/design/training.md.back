# Training models with EDS-NLP

### How do we compose models ?

> Problem: we can't initialize a module before knowing its input size
> Since input size (as well as other key parameters) can depend on the data, we can't directly
> instantiate a module from the config before the data has been seen in post_init

```python
import torch.nn


class TransformerEncoder(Component):
    def __init__(self, model_name):
        self.transformer = AutoModel.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

    def preprocess(self, doc):
        return {...}

    def collate(self, batch):
        return {...}

    def forward(self, batch):
        return {...}

    def postprocess(self, batch):
        return {...}

```

To compose a Transformer with a TextCNN encoder, we have multiple options:

1. **module-in-component**: a `TextCNN` standard (`torch.nn.Module`), instantiated in `post_init`, by a `TextCNNEncoder` (`Component`):

```python

@modules.register("text-cnn")
class TextCNN(torch.nn.Module):
    def __init__(self, kernel_sizes, input_size):
        super().__init__()
        self.kernel_sizes = kernel_sizes
        self.convs = ...

    def forward(self, embeddings, mask):
        return reshape(self.convs(embeddings)) + mask

# And now create a TextCNN module
@register("text-cnn")
class TextCNNEncoder(Module):
    def __init__(self, embedding, kernel_sizes):
        self.kernel_sizes = kernel_sizes
        self.embedding = embedding
        self.module = None

    def post_init(self, data):
        self.embedding.post_init(data)
        # We can now initialize the module
        size = self.embedding.output_size
        self.text_cnn = TextCNN(self.kernel_sizes, size)

    def preprocess(self, batch):
        return {"embedding": self.embedding.preprocess(batch)}

    def collate(self):
        return {...}

    def forward(self, batch):
        output = self.embedding(batch["embedding"])
        embeddings = self.text_cnn(output["embedding"], output["mask"])
        return {"embeddings": embeddings, "mask": output["mask"]}
```

```python
# And now create a TextCNN module

[cnn-de-tpj]
@module = "cnn-de-tpj"
input_size = "deferred"


@register("text-lstm")
class MyTextEncoder(Module):
    def __init__(self, embedding, kernel_sizes):
        self.kernel_sizes = kernel_sizes
        self.embedding = embedding
        self.module = None

    def post_init(self, data):
        self.embedding.post_init(data)
        # We can now initialize the module
        size = self.embedding.output_size
        self.text_cnn = TextLSTM(self.kernel_sizes, size)

    def preprocess(self, batch):
        return {"embedding": self.embedding.preprocess(batch)}

    def collate(self):
        return {...}

    def forward(self, batch):
        output = self.embedding(batch["embedding"])
        embeddings = self.text_cnn(output["embedding"])
        return {"embeddings": embeddings}
```

2. **component-only**: a TextCNN `Component` directly:

```python

# And now create a TextCNN module
class TextCNNEncoder(Component):
    def __init__(self, embedding, kernel_sizes):
        self.kernel_sizes = kernel_sizes
        self.embedding = embedding
        self.module = None

    def post_init(self, data):
        self.embedding.post_init(data)
        # We can now initialize the CNN layers
        size = self.embedding.output_size
        self.convs = ...

    def preprocess(self, batch):
        return {"embedding": self.embedding.preprocess(batch)}

    def collate(self):
        return {...}

    def forward(self, batch):
        output = self.embedding(batch["embedding"])
        return {"embeddings": reshape(self.convs(x)), "mask": output["mask"]}
```

We now don't need to repeat the initialization code but the module can only be used with the `Embedding` sub-component.

3**functional**: same as **component-only** but forward code is in a function:

```python

def apply_cnn(x, convs):
    return reshape(convs(x))

# And now create a TextCNN module
class TextCNNEncoder(Component):
    def __init__(self, embedding, kernel_sizes):
        self.kernel_sizes = kernel_sizes
        self.embedding = embedding
        self.module = None

    def post_init(self, data):
        self.embedding.post_init(data)
        # We can now initialize the CNN layers
        size = self.embedding.output_size
        self.convs = ...

    def preprocess(self, batch):
        return {"embedding": self.embedding.preprocess(batch)}

    def collate(self):
        return {...}

    def forward(self, batch):
        output = self.embedding(batch["embedding"])
        return {"embeddings": apply_cnn(output, self.convs), "mask": output["mask"]}
```

We now don't need to repeat the initialization code and the forward code can only be used outside of the `TextCNNEncoder` component.

4**generic-wrapper**:


```python

[embedding]

[base]
@factory = "trf"
...

[encoder_1]
@factory = "cnn"
output_size = 12

[span_pooler]
@factory = "span-pooler"


```


```python

class TextCNN(...):
   def __init__(self, kernels_sizes=..., output_size=...):
      self.kernels_sizex = ...

    def post_init(self):
        self.convs =


class EmbeddingWrapper(Component):
    def __init__(self, embedding, encoders):
        self.embedding = embedding
        self.encoders = torch.nn.ModuleList(encoders)

    def post_init(self, data):
        self.embedding.post_init(data)
        size = self.embedding.output_size
        for encoder in self.encoders:
            encoder.post_init(data, size=size)
            size = encoder.output_size

    def preprocess(self, batch):
        return {
            "embedding": self.embedding.preprocess(batch),
            **{f"encoder_{i}": encoder.preprocess(batch) for i, encoder in enumerate(self.encoders)}
        }

    def collate(self, batch):
        return ...

    def forward(self, batch):
        output = self.embedding(batch["embedding"])
        for i, encoder in enumerate(self.encoders):
            output = encoder({**output, **batch[f"encoder_{i}"]})
        return output

    def postprocess(self, batch):
        return self.embedding.postprocess(batch)
```

### Anatomy of components

#### Methods

- `post_init`: called after the config has been loaded, and before the first call to `forward` to initialize the module weights with the adequate shapes (embedding layers, embedding sizes, ...)
- `preprocess`: called on `Doc` objects to extract relevant features from the `Doc` objects.
   This means that any component that implements this method will have direct access to the `Doc` objects, and therefore is top-level.
- `collate`: collates batches of `preprocess` outputs into a single batch
- `forward`: called on the output of `collate` to compute the output of the component
- `postprocess`: called on the output of `forward` to annotate the input `Doc` objects with the output of the component

#### Examples:

| Component            | dynamic size        | need eg for init | prep & collate | `postprocess` | type      |
|----------------------|---------------------|------------------|----------------|---------------|-----------|
| `TransformerEncoder` | no                  | yes (vocab)      | yes            | no            | Encoder   |
| `TextCNNModule`      | create in post_init | no               | no             | no            | Layer     |
| `TextCNNEncoder`     | yes (prev layer)    | no               | no             | no            | Encoder   |
| `SentencePooler`     | yes (prev layer)    | maybe            | yes            | no            | Layer     |
| `NER`                | yes (prev layer)    | yes (labels)     | yes            | yes           | Component |
| `SpanClassifier`     | yes (prev layer)    | yes (labels)     | yes            | yes           | Component |
| `SpanEmbedding`      | yes (prev layer)    | yes (labels)     | yes            | yes           | Component |
| `LSTM`               | yes (prev layer)    | no               | no             | yes           | Layer     |
| `SpanTransformer`    | yes (prev layer)    | maybe            | yes            | no            | Layer     |

#### Classes
- **`torch.nn.Module`**: a standard PyTorch module, with a `forward` method only


Questionnements

- premiere pipe qui calcule un embedding
- deuxieme pipe qui classifie ces embeddings


### The initialization conundrum

Imagine the following pipeline:
- A tokenizer (every pipeline has one)
- A sentencizer
- A shared embedding layer for downstream components
- A sentence classifier component

We have a brat dataset containing sentence annotations at the entity level (one entity per sentence).

We need:
- fully annotated spaCy documents from which we will extract features to train the components
- to fill missing arguments from the configuration file, such as the list of labels for the sentence classifier component.

The problem is we might need to know which component is present in the pipeline to assign annotations on the documents and we might need documents to fill the missing components parameters.

Plan:
1. To obtain unannotated spaCy documents, we need to know the tokenizer of the pipeline
2. Then we need to annotate (automatically using the `sentencizer` component) sentences on the documents
3. Then we need to adapt entity annotations to sentence annotations
4. Then we need to gather labels of these sentences to initialize the classifier component

At the end of such a process, we obtain both the annotated documents and the initialized pipeline.
